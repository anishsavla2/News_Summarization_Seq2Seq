{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "FTuFmHwLekpO"
      },
      "outputs": [],
      "source": [
        "\n",
        "from spacy.lang.en import English\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import math\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from collections import Counter, OrderedDict\n",
        "from torchtext.vocab import vocab\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "4FMpwumLeuoK"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def saveDataToCache(data_path_cache,fileName):\n",
        "  \n",
        "  with open(data_path_cache, \"wb\") as f:\n",
        "    pickle.dump(fileName, f)"
      ],
      "metadata": {
        "id": "1eMo0YsPVZuz"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadCachedFile(data_path_cache_file):\n",
        "  with open(data_path_cache_file, \"rb\") as f:\n",
        "    return pickle.load(f)"
      ],
      "metadata": {
        "id": "m_CZShS_XuVD"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "ZG4KHeEwfChz"
      },
      "outputs": [],
      "source": [
        "class DataProcessor(Dataset):\n",
        "    def __init__(self, data_dir, set_name, tokenizer = None, use_cache_file = True, save_to_cache = True):\n",
        "\n",
        "        super().__init__()\n",
        "        self.src_data_path = os.path.join(data_dir, f\"{set_name}.txt.src\")\n",
        "        self.target_data_path = os.path.join(data_dir, f\"{set_name}.txt.tgt\")\n",
        "        self.src_data_path_cache = os.path.join(data_dir, f\"{set_name}.src.cached\")\n",
        "        self.target_data_path_cache = os.path.join(data_dir, f\"{set_name}.tgt.cached\")\n",
        "        self.src_idx = None\n",
        "        self.tgt_idx = None\n",
        "\n",
        "        if use_cache_file and os.path.isfile(self.src_data_path_cache):\n",
        "          self.src = loadCachedFile(self.src_data_path_cache)\n",
        "          print(\"Using cached file to load source paragraphs\")\n",
        "        else:\n",
        "          print(\"Loading sources from original file using tokenizer...\")\n",
        "          with open(self.src_data_path, \"r\") as f:\n",
        "            self.sourceFile = f.readlines()\n",
        "\n",
        "          self.sourceFile = np.array([tokenizer(text.strip()) for text in (tqdm(self.sourceFile) )], dtype=object)\n",
        "\n",
        "          if save_to_cache:\n",
        "            saveDataToCache(self.src_data_path_cache,self.sourceFile)\n",
        "\n",
        "\n",
        "        if use_cache_file and os.path.isfile(self.target_data_path_cache):\n",
        "          print(\"Using cached file to load targets\")\n",
        "          self.tgt = loadCachedFile(self.target_data_path_cache)\n",
        "        else:\n",
        "          print(\"Loading targets from original file using tokenizer...\")\n",
        "          with open(self.target_data_path, \"r\") as f:\n",
        "            self.targetFile = f.readlines()\n",
        "\n",
        "          self.targetFile = np.array([tokenizer(text.strip()) for text in (tqdm(self.targetFile) )], dtype=object)\n",
        "\n",
        "          if save_to_cache:\n",
        "            saveDataToCache(self.target_data_path_cache,self.targetFile)\n",
        "\n",
        "    def to_indexes(self, vocab):\n",
        "        self.src_idx = np.array([np.array(vocab(text)) for text in self.sourceFile], dtype=object)\n",
        "        self.tgt_idx = np.array([np.array(vocab(text)) for text in self.targetFile], dtype=object)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sourceFile)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.src_idx is not None:\n",
        "            return self.sourceFile[idx], self.src_idx[idx], self.targetFile[idx], self.tgt_idx[idx]\n",
        "        else:\n",
        "            return self.sourceFile[idx], self.targetFile[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "JpsfAaeyewqW"
      },
      "outputs": [],
      "source": [
        "tokenizer = English().tokenizer\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return text.split()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT1VUzcse9C6",
        "outputId": "7a7bfe84-e135-4306-b371-546cf8c0ad12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1\n",
            "Loading sources from original file using tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28722/28722 [00:01<00:00, 14467.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading targets from original file using tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28722/28722 [00:02<00:00, 12751.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sources from original file using tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1336/1336 [00:00<00:00, 16938.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading targets from original file using tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1336/1336 [00:00<00:00, 38997.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sources from original file using tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11490/11490 [00:00<00:00, 13774.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading targets from original file using tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11490/11490 [00:00<00:00, 92685.29it/s]\n"
          ]
        }
      ],
      "source": [
        "print(\"Test 1\")\n",
        "train_set = DataProcessor(\"data\", \"train\", tokenize_en)\n",
        "val_set = DataProcessor(\"data\", \"val\", tokenize_en)\n",
        "test_set = DataProcessor(\"data\", \"test\", tokenize_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "L6NEKEILj76x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00efbfb8-efec-44c5-8f51-ecd589dd3aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number tokens in vocab:  12277\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def construct_vocab(dataset, specials = [], min_freq = 0):\n",
        "    tokens = Counter([tok for example in tqdm(dataset.src + dataset.tgt) for tok in example ])\n",
        "    sorted_by_freq_tuples = [(item, count) for item, count in sorted(tokens.items(), key=lambda x: x[1], reverse=True) if count >= min_freq]\n",
        "    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "    for special in specials:\n",
        "        ordered_dict[special] = min_freq\n",
        "    return vocab(ordered_dict)\n",
        "\n",
        "UNK_TAG = \"<UNK>\"\n",
        "PAD_TAG = \"<PAD>\"\n",
        "START_TAG = \"<SOS>\"\n",
        "END_TAG = \"<EOS>\"\n",
        "MAX_UTTERANCE_LENGTH = 400\n",
        "MIN_VOCAB_FREQ = 320\n",
        "if os.path.isfile(f\"vocab.{MIN_VOCAB_FREQ}.pth\"):\n",
        "    vocab = torch.load(f\"vocab.{MIN_VOCAB_FREQ}.pth\")\n",
        "else:\n",
        "    vocab = construct_vocab(train_set, specials = [UNK_TAG, PAD_TAG, START_TAG, END_TAG], min_freq=MIN_VOCAB_FREQ)\n",
        "    torch.save(vocab, f\"vocab.{MIN_VOCAB_FREQ}.pth\")\n",
        "vocab.set_default_index(vocab[UNK_TAG])\n",
        "PAD_IDX = vocab[PAD_TAG]\n",
        "END_IDX = vocab[END_TAG]\n",
        "START_IDX = vocab[START_TAG]\n",
        "UNK_IDX = vocab[UNK_TAG]\n",
        "print(\"Number tokens in vocab: \", len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "oMAewwiw0_BZ"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "class Attention(nn.Module):\n",
        "  \n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        attention = attention.masked_fill(mask == 0, -torch.inf)\n",
        "        return F.softmax(attention, dim = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "Csw9ob0y1sPe"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "      \n",
        "        embedded = self.dropout(src)\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len, enforce_sorted=False)\n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "-k52aF9_2NUI"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention, pointer_generation = False):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.pointer_generation = pointer_generation\n",
        "        if self.pointer_generation:\n",
        "            self.pg_linear = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, 1)\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        self.fc_out = nn.Linear(dec_hid_dim + (enc_hid_dim * 2), dec_hid_dim)\n",
        "        self.out2 = nn.Linear(dec_hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask, src_extended_vocab = None, max_oov_vocab_size = 0):\n",
        "        \n",
        "        embedded = self.dropout(input.unsqueeze(0))\n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        weighted = torch.bmm(a.unsqueeze(1), encoder_outputs)\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        hidden = self.fc_out(torch.cat((output, weighted), dim = 1)) # <- probability distribution of words\n",
        "        word_dist = self.out2(hidden)\n",
        "\n",
        "        if self.pointer_generation:\n",
        "            src_extended_vocab = src_extended_vocab\n",
        "            prob_gen = torch.sigmoid(self.pg_linear(torch.cat((output, weighted, embedded), dim = 1))) # <- probability of generation\n",
        "            word_dist = (1 - prob_gen) * F.softmax(word_dist, dim = 1)\n",
        "            attn_dist = prob_gen * a\n",
        "\n",
        "            if max_oov_vocab_size > 0:\n",
        "                full_word_dist = torch.cat((word_dist, word_dist.new_zeros((word_dist.size(0), max_oov_vocab_size))), dim = 1)\n",
        "            final_word_dist = full_word_dist.scatter_add(1, src_extended_vocab, attn_dist)\n",
        "\n",
        "        else:\n",
        "            final_word_dist = F.softmax(word_dist, dim = 1)\n",
        "  \n",
        "        return final_word_dist, hidden.squeeze(0), a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "0-lgnN_X2pVS"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, input_dim, emb_dim, src_pad_idx, device, unk_idx):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        self.unk_idx = unk_idx\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg_forcing, teacher_forcing_ratio = 0.5, src_extended_vocab = None, max_oov_vocab_size = 0):\n",
        "        \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg_forcing.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        mask = self.create_mask(src)\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size + max_oov_vocab_size).to(self.device)\n",
        "        emb_src = self.embedding(src)\n",
        "        encoder_outputs, hidden = self.encoder(emb_src, src_len)\n",
        "        del src\n",
        "        input = trg_forcing[0,:]\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, _ = self.decoder(self.embedding(input), hidden, encoder_outputs, mask, src_extended_vocab, max_oov_vocab_size)\n",
        "            outputs[t] = output\n",
        "            top1 = output.argmax(1) \n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            input = trg_forcing[t] if teacher_force or (top1 >= trg_vocab_size).sum() > 0 else top1\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "nT4iVnM-3gd9"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip, device='cpu', pointer_generation = False):\n",
        "    print(\"Test 1\")\n",
        "    model.train()\n",
        "    print(\"Use pointer generator inside train : \",pointer_generation)\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(tqdm(iterator)):\n",
        "        \n",
        "        src, trg, trg_forcing, src_len, src_extended_vocab, oov_vocabs, max_oov_vocab_len, tgt_lens = batch\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        if pointer_generation:\n",
        "            src_extended_vocab = src_extended_vocab.to(device)\n",
        "            trg_forcing = trg_forcing.to(device)\n",
        "        else:\n",
        "            trg_forcing = trg\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, src_len, trg_forcing, 0.5, src_extended_vocab, max_oov_vocab_len)\n",
        "        output_dim = output.shape[-1]\n",
        "        gold_probs = torch.gather(output[:-1], 2, trg[1:].unsqueeze(2)).squeeze()\n",
        "        losses = -torch.log(gold_probs + 1e-15)\n",
        "        trg_mask = trg[1:] != model.src_pad_idx\n",
        "        sum_losses = torch.sum(losses[trg_mask], 0)\n",
        "        batch_avg_loss = sum_losses/tgt_lens.to(device)\n",
        "        loss = torch.mean(batch_avg_loss)\n",
        "        loss.backward()\n",
        "        epoch_loss += loss.item()\n",
        "        del loss, trg, output, output_dim, src, tgt_lens, sum_losses, batch_avg_loss, trg_mask\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion, device='cpu', pointer_generation = False):\n",
        "    \n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "            src, trg, trg_forcing, src_len, src_extended_vocab, oov_vocabs, max_oov_vocab_len, tgt_lens = batch\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "            if pointer_generation:\n",
        "                src_extended_vocab = src_extended_vocab.to(device)\n",
        "                trg_forcing = trg_forcing.to(device)\n",
        "            else:\n",
        "                trg_forcing = trg\n",
        "            \n",
        "            output = model(src, src_len, trg_forcing, 0, src_extended_vocab, max_oov_vocab_len)\n",
        "            gold_probs = torch.gather(output[:-1], 2, trg[1:].unsqueeze(2)).squeeze()\n",
        "            losses = -torch.log(gold_probs + 1e-15)\n",
        "            trg_mask = trg[1:] != model.src_pad_idx\n",
        "            sum_losses = torch.sum(losses[trg_mask], 0)\n",
        "            batch_avg_loss = sum_losses/tgt_lens.to(device)\n",
        "            loss = torch.mean(batch_avg_loss)\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "jRe9dK2m0o83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4ab502-9983-44b2-b10f-b3f9d2c64854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 2,823,286 trainable parameters\n",
            "Test 1\n",
            "Use pointer generator inside train :  True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 898/898 [05:17<00:00,  2.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 0s\n",
            "\tTrain Loss: 203.030 | Train PPL: 14962403532066137111443559386240591928212717857102004331316958890141541429284492609060864.000\n",
            "\t Val. Loss: 212.783 |  Val. PPL: 257339671337641771067015668402907794313894424541255406567160160680427343186454488763351433216.000\n",
            "Test 1\n",
            "Use pointer generator inside train :  True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 898/898 [05:18<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 02 | Time: 0m 0s\n",
            "\tTrain Loss: 198.664 | Train PPL: 189895082985984034268392440619665873586224457715139700492808304005415946649549215367168.000\n",
            "\t Val. Loss: 212.633 |  Val. PPL: 221504592060201843962448871826281350668098214011471265593261920676313390255544912072759312384.000\n",
            "Test 1\n",
            "Use pointer generator inside train :  True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 898/898 [05:15<00:00,  2.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 03 | Time: 0m 0s\n",
            "\tTrain Loss: 195.907 | Train PPL: 12065449847512422070783597971640897230608755913630207465322821000785725678732259098624.000\n",
            "\t Val. Loss: 211.989 |  Val. PPL: 116313083139314735669303506396628743304724077775753963246058958505713064933265083511982784512.000\n",
            "Test 1\n",
            "Use pointer generator inside train :  True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 898/898 [05:17<00:00,  2.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 04 | Time: 0m 0s\n",
            "\tTrain Loss: 193.475 | Train PPL: 1060078005163197011497185591304962071612426794236700913003486559475769761745531305984.000\n",
            "\t Val. Loss: 211.114 |  Val. PPL: 48471219025263342475040332550698066314837924105565221813479037330803458538463212899777118208.000\n",
            "Test 1\n",
            "Use pointer generator inside train :  True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 898/898 [05:16<00:00,  2.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 05 | Time: 0m 0s\n",
            "\tTrain Loss: 191.341 | Train PPL: 125419273385522831965501985131584530627153123911311429833231283766027303028061634560.000\n",
            "\t Val. Loss: 211.572 |  Val. PPL: 76620861583019635312225815117075244085589961900074225287589232971415038047814089048944803840.000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_set.to_indexes(vocab)\n",
        "val_set.to_indexes(vocab)\n",
        "test_set.to_indexes(vocab)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "pointer_generator_flag = True\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def collate_batch(batch):\n",
        "     src_lens, tgt_lens = [], []\n",
        "     out_of_vocab_words = []\n",
        "     for (source, source_idxs, tgt, tgt_idxs) in batch:\n",
        "         tgt_lens.append(len(tgt) + 2)\n",
        "         src_lens.append(min(len(source) + 2, MAX_UTTERANCE_LENGTH + 2))\n",
        "         if pointer_generator_flag:\n",
        "          oov_word_set = {}\n",
        "          for idx in np.where(source_idxs == UNK_IDX)[0]:\n",
        "               if idx < MAX_UTTERANCE_LENGTH and source[idx] not in oov_word_set:\n",
        "                    oov_word_set[source[idx]] = len(vocab) + len(oov_word_set)\n",
        "          out_of_vocab_words.append(oov_word_set)\n",
        "\n",
        "\n",
        "     max_src_len = min(max(src_lens), MAX_UTTERANCE_LENGTH + 2)\n",
        "     max_tgt_len = max(tgt_lens)\n",
        "     src_tensor = torch.full(size=(max_src_len, len(batch)), fill_value=PAD_IDX)\n",
        "     tgt_tensor = torch.full(size=(max_tgt_len, len(batch)), fill_value=PAD_IDX)\n",
        "\n",
        "     if pointer_generator_flag:\n",
        "          \n",
        "          src_extended_tensor = torch.full(size=(max_src_len, len(batch)), fill_value=PAD_IDX)\n",
        "          tgt_forcing_tensor = tgt_tensor.clone()\n",
        "     \n",
        "     for (i, (source, source_idxs, tgt, tgt_idxs)) in enumerate(batch):\n",
        "          tgt_tensor[1:tgt_lens[i] - 1, i] = torch.tensor(tgt_idxs, dtype=torch.int32)\n",
        "          tgt_tensor[0, i] = START_IDX\n",
        "          tgt_tensor[tgt_lens[i] - 1, i] = END_IDX\n",
        "          src_tensor[1:src_lens[i] - 1, i] = torch.tensor(source_idxs[:max_src_len - 2], dtype=torch.int32)\n",
        "          src_tensor[0, i] = START_IDX\n",
        "          src_tensor[src_lens[i] - 1, i] = END_IDX\n",
        "          if pointer_generator_flag:\n",
        "               tgt_forcing_tensor[:, i] = tgt_tensor[:, i]\n",
        "               oov_tgt_word_idxs = np.where(tgt_idxs == UNK_IDX)[0]\n",
        "               for idx in oov_tgt_word_idxs:\n",
        "                    if tgt[idx] in out_of_vocab_words[i]:\n",
        "                         tgt_tensor[1 + idx, i] = out_of_vocab_words[i][tgt[idx]]\n",
        "               oov_src_word_idxs = np.where(source_idxs == UNK_IDX)[0]\n",
        "               src_extended_tensor[:, i] = src_tensor[:, i]\n",
        "               for idx in oov_src_word_idxs:\n",
        "                    if idx < MAX_UTTERANCE_LENGTH:\n",
        "                         src_extended_tensor[1 + idx, i] = out_of_vocab_words[i][source[idx]]\n",
        "\n",
        "\n",
        "     src_lens = torch.tensor(src_lens, dtype=torch.int16)\n",
        "     tgt_lens = torch.tensor(tgt_lens, dtype=torch.int16)\n",
        "\n",
        "     return src_tensor, tgt_tensor, tgt_forcing_tensor if pointer_generator_flag else tgt_tensor, src_lens, src_extended_tensor.permute(1, 0) if pointer_generator_flag else None, out_of_vocab_words if pointer_generator_flag else None, max([len(s) for s in out_of_vocab_words]) if pointer_generator_flag else 0, tgt_lens\n",
        "\n",
        "\n",
        "NUM_WORKERS = 4\n",
        "train_iterator = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch, num_workers = NUM_WORKERS)\n",
        "val_iterator = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch, num_workers = NUM_WORKERS)\n",
        "test_iterator = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch, num_workers = 0)\n",
        "\n",
        "VOCAB_DIM = len(vocab)\n",
        "EMB_DIM = 64 #128 #256\n",
        "ENC_HID_DIM = 128 #256 #512\n",
        "DEC_HID_DIM = 128 #256 #512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "encoder = Encoder(EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "decoder = Decoder(VOCAB_DIM, EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn, pointer_generation = pointer_generator_flag)\n",
        "model = Seq2Seq(encoder, decoder, VOCAB_DIM, EMB_DIM, PAD_IDX, device, UNK_IDX).to(device)\n",
        "\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
        "\n",
        "N_EPOCHS = 5\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    end_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, device = device, pointer_generation = pointer_generator_flag)\n",
        "    valid_loss = evaluate(model, val_iterator, criterion, device = device, pointer_generation = pointer_generator_flag)\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model-best-new.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "if pointer_generator_flag:\n",
        "  torch.save(model.state_dict(), 'model-final-new-pg.pt')\n",
        "else:\n",
        "  torch.save(model.state_dict(), 'model-final-new.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "VBVMRJFLMlXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436cb2c8-af31-4a3e-8112-91bebb00c2ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42/42 [00:07<00:00,  5.84it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "model.eval()\n",
        "epoch_loss = 0\n",
        "trgs = []\n",
        "outputs = []\n",
        "srcs = []\n",
        "all_oov_vocabs = []\n",
        "with torch.no_grad():\n",
        "\n",
        "    \n",
        "    for i, batch in enumerate(tqdm(val_iterator)):\n",
        "        src, trg, trg_forcing, src_len, src_extended_vocab, oov_vocabs, max_oov_vocab_len, tgt_lens = batch\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        if pointer_generator_flag:\n",
        "            src_extended_vocab = src_extended_vocab.to(device)\n",
        "            trg_forcing = trg_forcing.to(device)\n",
        "        else:\n",
        "            trg_forcing = trg\n",
        "\n",
        "        output = model(src, src_len, trg_forcing, 0, src_extended_vocab, max_oov_vocab_len) #turn off teacher forcing\n",
        "        trg = trg.permute(1, 0)\n",
        "        trgs.extend(trg.cpu().numpy())\n",
        "        output = torch.argmax(output, dim = 2).permute(1, 0)\n",
        "        outputs.extend(output.cpu().numpy())\n",
        "        srcs.extend(src.permute(1, 0).cpu().numpy())\n",
        "        if oov_vocabs:\n",
        "            all_oov_vocabs.extend(oov_vocabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "JsDvGCU2MoFr"
      },
      "outputs": [],
      "source": [
        "def decode(seq, vocab, oov_vocab):\n",
        "    inverted_oov = {idx: word for word, idx in oov_vocab.items()}\n",
        "    if len(oov_vocab) == 0:\n",
        "        return vocab.lookup_tokens(seq)\n",
        "    else:\n",
        "        return [vocab.lookup_token(idx) if idx < len(vocab) else inverted_oov[idx] for idx in seq]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "DnbI0FqIMpuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e868bf5-ef0e-49e4-e06e-206e050f485e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "<SOS> -lrb- cnn -rrb- a facebook post by actor ashton kutcher <UNK> the lack of <UNK> changing tables in public men 's rooms has parents talking . the new father -- he and partner <UNK> <UNK> welcomed baby <UNK> <UNK> in october -- complained to his followers that he had yet to encounter a changing table in the public <UNK> he visits . he offered to give a social media <UNK> to the first business where he found a <UNK> table in the men 's room . the post had <UNK> more than <UNK> comments as of wednesday morning . lots of folks offered up places kutcher should <UNK> , such as walmart and <UNK> barrel , where they say changing tables <UNK> . some dads said they did n't have a problem finding changing tables , but it may be because they 're <UNK> more <UNK> <UNK> than the hollywood star . other posters said `` family <UNK> '' would take care of the problem altogether . do modern dads get enough credit ? many praised kutcher for raising the issue : `` thank you for doing this . this is not just an issue for dad 's such as yourself who are awesome , but so many of the families i know who have two <UNK> have this issue all the time , '' wrote one poster . another mom agreed : `` my boyfriend was taken <UNK> when he had to get a key for the family change room instead of just going into the men 's with our son because they had no change table . it does n't make any sense . gender equality needs to go both ways . '' no update yet on whether kutcher has encountered a <UNK> station in a men 's room . dad blogger 's death <UNK> renewed push to <UNK> ` amazon mom ' <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Target Summary Text:\n",
            "<SOS> actor ashton kutcher complained on facebook that men 's rooms do n't have diapering tables . he offered to give free publicity to the first establishment where he encountered one . kutcher and his partner , mila kunis , welcomed baby wyatt isabelle in october . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Generated Summary Text:\n",
            "the kutcher kutcher kutcher the to in in . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <EOS> . <EOS> . <EOS> . <EOS> . <EOS>\n"
          ]
        }
      ],
      "source": [
        "idx = 41\n",
        "print(\"Original Text:\")\n",
        "print(\" \".join(vocab.lookup_tokens(srcs[idx])))\n",
        "print(\"Target Summary Text:\")\n",
        "print(\" \".join(decode(trgs[idx], vocab, all_oov_vocabs[idx] if idx < len(all_oov_vocabs) else {})))\n",
        "print(\"Generated Summary Text:\")\n",
        "print(\" \".join(decode(outputs[idx], vocab, all_oov_vocabs[idx] if idx < len(all_oov_vocabs) else {})))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "rD9ELDMBMq-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70638b9a-e8fe-4e9f-9ca3-edebd2bec730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1336/1336 [00:00<00:00, 7551.80it/s]\n",
            "100%|██████████| 1336/1336 [00:00<00:00, 6936.80it/s]\n"
          ]
        }
      ],
      "source": [
        "trialOutput = [\" \".join(decode(outputs[i], vocab, all_oov_vocabs[i] if idx < len(all_oov_vocabs) else {})) for i in tqdm(range(len(outputs)))]\n",
        "referenceOutput = [\" \".join(decode(trgs[i], vocab, all_oov_vocabs[i] if idx < len(all_oov_vocabs) else {})) for i in tqdm(range(len(trgs)))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "ui8VIPsNMsIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91773739-978a-4e27-c66c-27ded61794bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge-1': {'f': 0.1780476423461404,\n",
              "  'p': 0.5225782527445748,\n",
              "  'r': 0.10958464429582805},\n",
              " 'rouge-2': {'f': 0.009309292957345512,\n",
              "  'p': 0.018953538970449713,\n",
              "  'r': 0.006407892480837956},\n",
              " 'rouge-l': {'f': 0.1643511496129068,\n",
              "  'p': 0.4828030028364653,\n",
              "  'r': 0.10115495334657565}}"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ],
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "rouge.get_scores(trialOutput, referenceOutput, avg = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "qlW_9IDPMvQy"
      },
      "outputs": [],
      "source": [
        "with open(\"predictions.baseline.txt\", \"w\") as f:\n",
        "    f.writelines([h + \"\\n\" for h in trialOutput])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "machine_shape": "hm",
      "name": "NLP203_Homework1_AnishSavla_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}